{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Links for product and rating.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE-PeUzWZT6G"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "import urllib\n",
        "import bs4 as bs\n",
        "from bs4 import SoupStrainer\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request, urllib.error, urllib.parse\n",
        "import time\n",
        "from urllib.request import FancyURLopener  # This is library that helps us create the headless browser\n",
        "import random\n",
        "from random import choice  #This library helps pick a random item from a list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rank = []\n",
        "product_link = []\n",
        "name = []\n",
        "avg_rating = []\n",
        "rating_link = []\n",
        "rating_count = []\n",
        "prime = []"
      ],
      "metadata": {
        "id": "LwQ7T_yiZ2pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_agents = [\n",
        "    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
        "    'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16',\n",
        "    'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'\n",
        "]\n",
        "\n",
        "class MyOpener(FancyURLopener, object):\n",
        "    version = choice(user_agents)\n",
        "\n",
        "myopener = MyOpener()\n",
        "page=myopener.open(link)\n",
        "\n",
        "# time.sleep(5)\n",
        "time.sleep(random.uniform(0,1))  #sleep time follows uniform distribution [5,10] with mean is 7.5\n",
        "\n",
        "html = page.read().decode('utf-8')\n",
        "soup = BeautifulSoup(html)\n",
        "\n",
        "last_page = False\n",
        "\n",
        "while last_page == False:\n",
        "    \n",
        "    total = soup.find_all('li', class_ = 'zg-item-immersion')\n",
        "\n",
        "    for i in range(0,len(total)):\n",
        "        \n",
        "        # rank of the product\n",
        "        if total[i].find('span', class_ = 'zg-badge-text').getText() != None:\n",
        "            rank.append(total[i].find('span', class_ = 'zg-badge-text').getText())\n",
        "        else:\n",
        "            rank.append('not found')\n",
        "        \n",
        "        # product link\n",
        "        if total[i].find('a', class_=\"a-link-normal\") != None :\n",
        "            product_link.append(total[i].find('a', class_=\"a-link-normal\")['href'])\n",
        "        else:\n",
        "            product_link.append('not found')\n",
        "        \n",
        "        # Name of the product\n",
        "        if total[i].find('a', class_ = \"a-link-normal\") != None:\n",
        "            name.append(total[i].find('a', class_ = \"a-link-normal\").getText().replace('\\n', ''))\n",
        "        else:\n",
        "            name.append('not found')\n",
        "        \n",
        "        # Average rating for the product\n",
        "        if total[i].find_all('span', class_=\"a-icon-alt\") != None:\n",
        "            avg_rating.append(total[i].find_all('span',class_ = \"a-icon-alt\"))\n",
        "        else:\n",
        "            avg_rating.append('no rating')\n",
        "        \n",
        "        # review link\n",
        "        if total[i].find('a',class_ = \"a-size-small a-link-normal\") != None:\n",
        "            rating_link.append(total[i].find('a',class_ = \"a-size-small a-link-normal\")['href'])\n",
        "        else:\n",
        "            rating_link.append('not found')\n",
        "        \n",
        "        # Number of users who gave the rating \n",
        "        if total[i].find('a',class_ = \"a-size-small a-link-normal\") != None:\n",
        "            rating_count.append(total[i].find('a',class_ = \"a-size-small a-link-normal\").getText())\n",
        "        else:\n",
        "            rating_count.append('not found')\n",
        "        \n",
        "        # checking if prime service is available or not\n",
        "        if total[i].find('i', class_=\"a-icon a-icon-prime a-icon-small\") != None:\n",
        "            prime.append('prime')\n",
        "        else:\n",
        "            prime.append('no prime')\n",
        "            \n",
        "    # identifying if there is next page or not\n",
        "    if html.find('class=\"a-last\"') != -1 :       \n",
        "         \n",
        "        next_url = soup.find_all('li', class_ = 'a-last')[0].find('a')['href']\n",
        "\n",
        "        class MyOpener(FancyURLopener, object):\n",
        "            version = choice(user_agents)\n",
        "\n",
        "        myopener = MyOpener()\n",
        "        page=myopener.open(next_url)\n",
        "        # time.sleep(5)\n",
        "        time.sleep(random.uniform(0,1))  #sleep time follows uniform distribution [5,10] with mean is 7.5\n",
        "\n",
        "        html = page.read().decode('utf-8')\n",
        "        soup = BeautifulSoup(html)       \n",
        "    \n",
        "    else:\n",
        "        last_page = True"
      ],
      "metadata": {
        "id": "BNDGD_9sZ577"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appending the lists into a dataframe\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(list(zip(rank, product_link, name , avg_rating, rating_link, rating_count,prime)), \n",
        "            columns =['rank', 'product_link', 'name' , 'avg_rating', 'rating_link', 'rating_count', 'prime'])"
      ],
      "metadata": {
        "id": "7tiJiHUEZ9Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# writing the dataframe to a csv file\n",
        "import csv\n",
        "df.to_csv('/Users/ruthvik/Downloads/pc.csv', index = False)"
      ],
      "metadata": {
        "id": "lItkF9kYZ_l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hLIVbF0paCf2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}